{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnpr1VPKUwY9"
      },
      "source": [
        "[Lukas Vasquez Verdejo y Ken Miyake M.]\n",
        "\n",
        "En esta tarea van a crear una red neuronal que clasifique mensajes como spam o no spam. Lo primero es descargar la data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkXXLb0VUmFX",
        "outputId": "3fe4679c-a7c6-44d3-dad2-506ff904eed2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-12-05 21:08:13--  https://www.ivan-sipiran.com/downloads/spam.csv\n",
            "Resolving www.ivan-sipiran.com (www.ivan-sipiran.com)... 66.96.149.31\n",
            "Connecting to www.ivan-sipiran.com (www.ivan-sipiran.com)|66.96.149.31|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 471781 (461K)\n",
            "Saving to: ‘spam.csv’\n",
            "\n",
            "spam.csv            100%[===================>] 460.72K   627KB/s    in 0.7s    \n",
            "\n",
            "2022-12-05 21:08:15 (627 KB/s) - ‘spam.csv’ saved [471781/471781]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.ivan-sipiran.com/downloads/spam.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9567d6oVknI"
      },
      "source": [
        "Los datos vienen en un archivo CSV que contiene dos columnas \"text\" y \"label\". La columna \"text\" contiene el texto del mensaje y la columna \"label\" contiene las etiquetas \"ham\" y \"spam\". Un mensaje \"ham\" es un mensaje que no se considera spam.\n",
        "\n",
        "# Tarea\n",
        "El objetivo de la tarea es crear una red neuronal que clasifique los datos entregados. Para lograr esto debes:\n",
        "\n",
        "\n",
        "\n",
        "*   Implementar el pre-procesamiento de los datos que creas necesario.\n",
        "*   Particionar los datos en 70% entrenamiento, 10% validación y 20% test.\n",
        "*   Usa los datos de entrenamiento y valiadación para tus experimentos y sólo usa el conjunto de test para reportar el resultado final.\n",
        "\n",
        "Para el diseño de la red neuronal puedes usar una red neuronal recurrente o una red basada en transformers. El objetivo de la tarea no es obtener el performance ultra máximo, sino entender qué decisiones de diseño afectan la solución de un problema como este. Lo que si es necesario (como siempre) es que discutas los resultados y decisiones realizadas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqMwdCZhv4XS"
      },
      "source": [
        "# Introducción\n",
        "\n",
        "En el presente informe se trabajará con un dataset de correos electrónicos los cuales poseen dos clases: ham y spam. Se intentará clasificar los correos  mediante  el uso  de modelos  de redes neuronales, en particular, RNN y Transformers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff1B4GvCwB7A"
      },
      "source": [
        "## Descripción de Data-Set\n",
        "\n",
        "El Data Set  a utilizar consta de 5572 filas  correspondientes a spam (746) , ham (4617) los cuales se encuentran correctamente etiquetados. El resto de las filas del dataset son corruptas, por ejemplo, columnas en la etiqueta que contienen  basura o textos que corresponden a strings vacíos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPDnLTexvMNg"
      },
      "source": [
        " ### Carga de Datos\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pmzo1gcVXvY",
        "outputId": "0478edaa-a06f-4f6a-b914-8f57c31c5040"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cantidad de mensajes: 5572\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "#Primero se cargan todos los datos  del csv\n",
        "data=pd.read_csv('spam.csv')\n",
        "text=data['text']\n",
        "labels=data['label']\n",
        "#Copia de los datos con los que trabajará BERT\n",
        "original_text=data['text']\n",
        "original_labels=data['label']\n",
        "print('Cantidad de mensajes:' ,len(text))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXjKZ8gry-DR"
      },
      "source": [
        "### Pre-Procesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZyVwA6CzDq1"
      },
      "source": [
        "Necesitamos separar los mensajes de los labels.Para esto el procedimiento es el siguiente:\n",
        "<ul>\n",
        "<li>Eliminamos los signos de puntuación en los textos.\n",
        "<li> Dejamos strings en minúsculas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFwB85ymy9Cd",
        "outputId": "2d59414f-6ba4-4ea0-88be-3139682e1876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n"
          ]
        }
      ],
      "source": [
        "from string import punctuation\n",
        "\n",
        "text=text.astype(str).apply(lambda x: x.lower())\n",
        "text_dep=text.astype(str).apply(lambda x: ''.join([c for c in x if c not in punctuation]))\n",
        "print(punctuation)\n",
        "print(text_dep[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRB8zbAbG1iZ"
      },
      "source": [
        "Generamos un diccionario con  cada palabra  en los emails, esto nos servirá para  posteriormente pasarlos como paramteros a nuestra red neuronal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh7RT5Da3eCG",
        "outputId": "41534688-b2ca-434b-f89c-e3f4a43bd617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Palabras únicas: 9396\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "words=''.join(text_dep.astype(str).apply(lambda x: x+' ')).split() #juntamos todas las filas en un string  agregamos un espacio al final para el split\n",
        "counts = Counter(words) #Construye un diccionario de palabras. Las claves son las palabras y los valores son la frecuencia\n",
        "vocab = sorted(counts, key=counts.get, reverse=True) #Ordenamos la palabras por frecuencia\n",
        "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)} #Construimos diccionario para mapear palabra a número entero. Empezamos los índices en 1\n",
        "\n",
        "#Ahora convertimos cada palabra de los reviews en índices\n",
        "encoded_text = []\n",
        "for mail in text_dep.tolist():\n",
        "  encoded_text.append([vocab_to_int[word] for word in mail.split()])\n",
        "\n",
        "#Palabras en el dict\n",
        "print('Palabras únicas:', len(vocab_to_int))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFopjuEgVKWM"
      },
      "source": [
        "Realizamos la codificación para cada palabra en labels.Si es spam entonces se deja con 1, si no 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fzg256QVFfV",
        "outputId": "1d31884c-b00c-427b-8d39-3832bbdaa9b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spam  746\n",
            "ham  4617\n",
            "garbage label 209\n",
            "spam + ham 5363\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "labels_list = labels.tolist()\n",
        "encoded_labels = np.array([1 if label == 'spam' else 0 if label=='ham' else 2  for label in labels_list])\n",
        "print('spam ', sum(encoded_labels==1))\n",
        "print('ham ', sum(encoded_labels==0))\n",
        "print('garbage label', sum(encoded_labels==2))\n",
        "\n",
        "print('spam + ham',sum(encoded_labels==1)+sum(encoded_labels==0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djmhn2fowxsN"
      },
      "source": [
        "Realizamos un conteo del largo asociado a cada mail.Podemos apreciar la distribución de estos datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "Gu8GQkng5UcY",
        "outputId": "2e73c26a-d559-4d6d-9e42-978bc706d8e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mensajes de longitud cero: 2\n",
            "Máxima longitud: 171\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Amount')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "text_lens= Counter([len(x) for x in encoded_text]) #Contamos cuantas palabras hay en cada review\n",
        "print(\"Mensajes de longitud cero:\", text_lens[0])\n",
        "print('Máxima longitud:', max(text_lens))\n",
        "\n",
        "x= [i for i in range(0,172)]\n",
        "y= [text_lens[i] for i in range(0,172)]\n",
        "\n",
        "\n",
        "fig ,ax =plt.subplots()\n",
        "ax.bar(x,y)\n",
        "ax.set_xlabel('Mail length')\n",
        "ax.set_ylabel('Amount')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtx5nr8F8mA7"
      },
      "source": [
        "Eliminamos los textos de largo 0 y los textos con labels basura."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XT8uPXx1-0LS",
        "outputId": "649af888-b544-4d29-e442-ba60a9861383"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mensajes antes de eliminación: 5572\n",
            "Reviews después de eliminación (zeros and garbage label): 5361\n"
          ]
        }
      ],
      "source": [
        "print('Mensajes antes de eliminación:', len(encoded_text))\n",
        "\n",
        "#Extraemos los índices de todos los reviews que tienen longitud > 0\n",
        "non_zero_idx = [ii for ii, text in enumerate(encoded_text) if len(text)!=0]\n",
        "#Extraemos los indices de los mensajes mal etiquetados\n",
        "non_zero_idx = [ii for ii in non_zero_idx if encoded_labels[ii] !=2]\n",
        "\n",
        "#Nos quedamos solo con los reviews con longitud > 0\n",
        "encoded_nz_texts = [encoded_text[ii] for ii in non_zero_idx]\n",
        "\n",
        "#Lo mismo con los labels\n",
        "encoded_nz_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])\n",
        "\n",
        "\n",
        "print('Reviews después de eliminación (zeros and garbage label):', len(encoded_nz_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWleP_IAImIP"
      },
      "source": [
        "Dejamos un largo fijo para  los mensajes , esto para uniformizar la entrada  de los inputs y poder computarlos en batches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54jQRR2AIX2X"
      },
      "source": [
        "Definimos el largo para las sequencias.Los mensajes con un largo menor se completan con 0's al inicio de la secuencia.Si tienen un largo mayor, simplemente se truncan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EurK6LTiKlNL"
      },
      "outputs": [],
      "source": [
        "def pad_features(encoded_nz_text, seq_length):\n",
        "  features = np.zeros((len(encoded_nz_text), seq_length), dtype=int)\n",
        "\n",
        "  #Para cada review, se coloca en la matriz\n",
        "  for i, row in enumerate(encoded_nz_text):\n",
        "    features[i, -len(row):] = np.array(row)[:seq_length]\n",
        "\n",
        "  return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9weHiWONQo3l"
      },
      "source": [
        "### Partición de Datos\n",
        "\n",
        "Procedemos a separar los datos en en train (70%), validation (10%)  y test (20%)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d9v5p0SONOG",
        "outputId": "1c818e53-28fa-4bc7-ea91-405e09e85167"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5361, 171)\n"
          ]
        }
      ],
      "source": [
        "#Probamos el padding\n",
        "seq_length = 171\n",
        "\n",
        "features = pad_features(encoded_nz_texts, seq_length=seq_length)\n",
        "\n",
        "print(features.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlZjwJmuQope",
        "outputId": "79b45425-3fdb-4570-ff08-e343c22d2321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\t\t\tFeatures:\n",
            "Train set: \t\t(3752, 171) \n",
            "Validation set: \t(530, 171) \n",
            "Test set: \t\t(1079, 171)\n"
          ]
        }
      ],
      "source": [
        "split_frac = 0.7\n",
        "\n",
        "## split data into training, validation, and test data (features and labels, x and y)\n",
        "split_idx = int(len(features)*split_frac)\n",
        "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
        "train_y, remaining_y = encoded_nz_labels[:split_idx], encoded_nz_labels[split_idx:]\n",
        "\n",
        "test_idx = int(len(remaining_x)*0.33)\n",
        "\n",
        "\n",
        "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
        "\n",
        "## print out the shapes of your resultant feature data\n",
        "print(\"\\t\\t\\tFeatures:\")\n",
        "print(\"Train set: \\t\\t{}\".format(train_x.shape),\n",
        "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSh9HZUnfr5T"
      },
      "source": [
        "### Data Loaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5uzUTDlfZMw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# crear Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 40\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size,  drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5RbE3gqoCZ_",
        "outputId": "a4277759-1f77-4d61-d3c6-d548178e115b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No GPU available, training on CPU.\n"
          ]
        }
      ],
      "source": [
        "# Chequear si tenemos GPU\n",
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SIqwYahxrfO"
      },
      "source": [
        "# Experimentos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h99AJw5kx_nb"
      },
      "source": [
        "### Descripción de modelos\n",
        "Para abordar este problema se hará uso  principalmente de  dos redes LSTM (y bidirectional LSTM) y BERT en 3 experimentos.\n",
        "La LSTM (long short term memory) es un tipo de red neuronal recurrente  que surge como solución al problema de  “vanishing - gradients” o “exploding- gradients”.La  idea principal de LSTM es  que posee  2 vías de aprendizaje  para secuencias , la puerta de entrada de los estados ocultos de una red recurrente convencional (corto plazo) y una memoria  dada por una función de “forgetting” (largo plazo) . La presencia de esta memoria largo plazo actúa como un bypass  entre las capas finales con las iniciales  evitando  la exploción en la retropropagación de errores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dT8HsqZyMnC"
      },
      "source": [
        "## Experimento 1: LSTM\n",
        "\n",
        "Para este experimento se entrenará una red LSTM normal limitando el largo de la secuencia a 170 (mail de largo máximo).\n",
        "\n",
        "\n",
        "## Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Net7HHvol9G"
      },
      "outputs": [],
      "source": [
        "#Creamos la red neuronal\n",
        "import torch.nn as nn\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5,bidirectional=False):\n",
        "\n",
        "        super(SentimentRNN, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Capas embedding y LSTM\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers,\n",
        "                            dropout=drop_prob, batch_first=True,bidirectional=bidirectional)\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        # dropout\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "\n",
        "        # Capa lineal y sigmoide\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "        #Tomamos solo el último valor de salida del LSTM\n",
        "        lstm_out = lstm_out[:,-1,:]\n",
        "\n",
        "        # dropout y fully-connected\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        # sigmoide\n",
        "        sig_out = self.sig(out)\n",
        "\n",
        "        # retornar sigmoide y último estado oculto\n",
        "        return sig_out, hidden\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # Crea dos nuevos tensores con tamaño n_layers x batch_size x hidden_dim,\n",
        "        # inicializados a cero, para estado oculto y memoria de LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "\n",
        "        if(train_on_gpu):\n",
        "          hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                   weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "          hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                   weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "\n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMaKVbWYo2bw",
        "outputId": "2a4a6832-e9f7-4413-c4cc-9992840aef81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(9397, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Instanciamos la red\n",
        "vocab_size = len(vocab_to_int) + 1 # +1 for zero padding + our word tokens\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIJBXmS5qJU1"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4qjFxq9qMDZ"
      },
      "outputs": [],
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6-16lO6qOpt",
        "outputId": "81f4c8bc-b1f0-4f05-9611-01e4e8e0de9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época: 2/4... Paso: 100... Loss: 0.000138... Val Loss: 0.078054\n",
            "Época: 3/4... Paso: 200... Loss: 0.005729... Val Loss: 0.125734\n",
            "Época: 4/4... Paso: 300... Loss: 0.000202... Val Loss: 0.100389\n"
          ]
        }
      ],
      "source": [
        "# training params\n",
        "\n",
        "epochs = 4\n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# Enviar red al GPU\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "net.train()\n",
        "# Bucle de entrenamiento\n",
        "for e in range(epochs):\n",
        "    # Inicializar estado oculto\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # Bucle para batchs\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Crear nuevas variables para estados ocultos, sino se haría\n",
        "        # backprop para todos los pasos del bucle\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        net.zero_grad()\n",
        "\n",
        "        # Hacer pasada forward\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        # Calcular loss y hacer backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # gradient clipping\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Mensajes\n",
        "        if counter % print_every == 0:\n",
        "            # Validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if(train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Época: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Paso: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG0Er5YbLD89"
      },
      "source": [
        "### Calculamos el Test Accuracy\n",
        "En el siguiente apartado se calcula el accuracy. También se calculará el accuracy especifico a cada clase (fracción  de predicciones correctas para spam y para  ham) para dilucidar de mejor manera el desempeño del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6q8oDETIFYz",
        "outputId": "1b3f2397-9c33-4fc9-ff43-09d9bf1c0b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-36ad9fcfbe6c>:40: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  spam_correct+=pred_np[spam_mask].tolist().count(1)\n",
            "<ipython-input-19-36ad9fcfbe6c>:41: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
            "  ham_correct+=pred_np[ham_mask].tolist().count(0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.107\n",
            "Ham Acc: 0.997\n",
            "Spam Acc: 0.901\n",
            "Test accuracy: 0.948\n"
          ]
        }
      ],
      "source": [
        "# Calcular accuracy de test\n",
        "\n",
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "spam_correct=0\n",
        "spam=0\n",
        "ham=0\n",
        "ham_correct=0\n",
        "# Iniciar estado oculto\n",
        "h = net.init_hidden(batch_size)\n",
        "\n",
        "net.eval()\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    output, h = net(inputs, h)\n",
        "\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "\n",
        "    # Convertir probabilidades a clases (0,1)\n",
        "    pred = torch.round(output.squeeze())\n",
        "\n",
        "    # Comparar predicciones a labels\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "    pred_np=pred.detach().cpu().numpy()\n",
        "    label_np=labels.float().detach().cpu().numpy()\n",
        "\n",
        "    spam_mask=[label_np==1]\n",
        "    ham_mask=[label_np==0]\n",
        "    spam+=label_np.tolist().count(1)\n",
        "    ham+=label_np.tolist().count(0)\n",
        "\n",
        "    spam_correct+=pred_np[spam_mask].tolist().count(1)\n",
        "    ham_correct+=pred_np[ham_mask].tolist().count(0)\n",
        "\n",
        "\n",
        "# -- stats! -- ##\n",
        "# avg test loss\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "# Accuracy de test\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Ham Acc: {:.3f}\".format(ham_correct/ham))\n",
        "print(\"Spam Acc: {:.3f}\".format(spam_correct/spam))\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede observar el modelo  presenta  un menor performance cuando lo utilizamos para identificar spam.Esto puede deberse a la  gran cantidad de \"ham\" presentes en el dataloader del entrenamiento en comparación a  los \"spam\".En los ejemplos siguientes (inferencias)  se muestra que el modelo no es robusto  en la identificación  de algunos \"spam\"."
      ],
      "metadata": {
        "id": "Q2TOE_fz90OR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CVVSRlCLAo8"
      },
      "source": [
        "## Inferencia\n",
        "Es posible igrsar inputs para probar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSW56a0PLMxw"
      },
      "outputs": [],
      "source": [
        "from string import punctuation\n",
        "\n",
        "def tokenize_review(test_mail):\n",
        "    test_mail = test_mail.lower()\n",
        "    test_text = ''.join([c for c in test_mail if c not in punctuation])\n",
        "    test_words = test_text.split()\n",
        "    test_ints = []\n",
        "    test_ints.append([vocab_to_int[word] for word in test_words if word in vocab_to_int])#alterado\n",
        "    print('palabras desconocidas :',[x for x in test_words if x not in vocab_to_int])\n",
        "    return test_ints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5X80V5a8LSxu"
      },
      "outputs": [],
      "source": [
        "def predict(net, test_review, sequence_length=200):\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    test_ints = tokenize_review(test_review)\n",
        "\n",
        "    seq_length = sequence_length\n",
        "    features = pad_features(test_ints, seq_length)\n",
        "\n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "\n",
        "    batch_size = feature_tensor.size(0)\n",
        "\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    if(train_on_gpu):\n",
        "      feature_tensor = feature_tensor.cuda()\n",
        "\n",
        "    output, h = net(feature_tensor, h)\n",
        "\n",
        "    pred = torch.round(output.squeeze())\n",
        "    print('Valor predicho, antes del redondeo: {:.6f}'.format(output.item()))\n",
        "\n",
        "    # print custom response based on whether test_review is pos/neg\n",
        "    if(pred.item()==1):\n",
        "      print('spam')\n",
        "    else:\n",
        "      print('ham ')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo 1:"
      ],
      "metadata": {
        "id": "u4REKdYVL4G_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maowr80fLZ4b",
        "outputId": "817fc0ee-14f8-42ca-b2af-178dc96231cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47\n",
            "palabras desconocidas : ['sustainable', 'deadline', 'university’s', 'master', 'health', 'topranked', 'health', 'nov', '2023', 'cohort']\n",
            "Valor predicho, antes del redondeo: 0.684975\n",
            "spam\n"
          ]
        }
      ],
      "source": [
        "seq_length=40\n",
        "text=\"\"\"Are you ready to lead sustainable change in your community? The final deadline for Boston University’s online Master of Public Health from its top-ranked School of Public Health is almost here.*\n",
        "\n",
        "Apply by Nov. 1 for the Spring 2023 cohort.\n",
        "No GRE scores are required to apply..\"\"\"\n",
        "\n",
        "predict(net,text, len(text.split()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejemplo 2:"
      ],
      "metadata": {
        "id": "7JLYiW5KL_He"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length=40\n",
        "text=\"\"\"\n",
        "Ready to maximize your workflow? Saving time with stock 3D is great, and saving money is\n",
        "even better. Take up to 50% off a massive selection of our 3D model catalog during our Flash Sale!\"\"\"\n",
        "\n",
        "predict(net,text, len(text.split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMfN-zFmMCNn",
        "outputId": "5fcee114-45f8-4921-ac46-67cb0fdbca36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35\n",
            "palabras desconocidas : ['workflow', 'saving', 'saving', 'catalog']\n",
            "Valor predicho, antes del redondeo: 0.000091\n",
            "ham \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AYx6ejUOcC8"
      },
      "source": [
        "# Experimento 2: Transformer BERT (Bidirectional Encoder Representations from Transformers)\n",
        "\n",
        "Si bien el uso de LSTM para el problema parece ser suficiente para obtener resultados satisfactorios, se experimentará con BERT dado que es parte de la familia de modelos que forman parte del estado del arte en lo que a NLP se refiere, por lo que esperamos que los resultados sean superiores a los obtenidos hasta ahora. El pipeline usado se obtuvo del [documento](https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP), en particular, ser realizará fine-tuning con BERT mediante el uso de la libreria Pytorch de HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQYkm41OOby5",
        "outputId": "5cd1fd6c-c773-41aa-bfbb-3c474c787786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "#En esta celda se intentará usar la GPU, en caso de que no se pueda se usará la CPU\n",
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L98MDk6_buc",
        "outputId": "67320f11-703c-4825-927f-f4e780e7d99d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 12.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |███████████████████████         | 5.5 MB 5.9 MB/s eta 0:00:01"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IzqiblZK9L2"
      },
      "source": [
        "Descargamos el tokenizador de BERT, nos permitirá \"tokenizar\" el texto del dataset y dejar los datos con el formato con el cual BERT podrá procesarlos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqjHMtRS_yNs"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goig__nLD__G",
        "outputId": "194c507f-1f4c-4777-d8b4-2052a5cca566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n"
          ]
        }
      ],
      "source": [
        "print(original_text[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1bzdbkILRXI"
      },
      "source": [
        "**Pre-procesamiento de los datos** \\\\\n",
        "Aquí pre-procesaremos los datos. Se eliminarán filas con datos nulos y/o que contengan basura (algunos labels contienen datos basura)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9NF4phxB1T-"
      },
      "outputs": [],
      "source": [
        "datos_texto=[]\n",
        "datos_labels=[]\n",
        "\n",
        "for i, sentence in enumerate(original_text):\n",
        "  if (type(sentence)== type(\"text\")) and (len(sentence)>0) and ((original_labels[i]==\"spam\") or (original_labels[i]==\"ham\")):\n",
        "    datos_texto.append(sentence)\n",
        "    datos_labels.append(original_labels[i])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlLzrTTQHaZP"
      },
      "outputs": [],
      "source": [
        "count_spam=0\n",
        "count_ham=0\n",
        "for i, etiqueta in enumerate(datos_labels):\n",
        "  if(etiqueta==\"spam\"):\n",
        "    datos_labels[i]=1\n",
        "    count_spam+=1\n",
        "  else:\n",
        "    datos_labels[i]=0\n",
        "    count_ham+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EPvx81yL4Nj"
      },
      "source": [
        "Revisamos con cuantos datos nos quedamos:\n",
        "\n",
        "1.   Spam= 746\n",
        "2.   Ham= 4617\n",
        "3. Total= 5363"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPCFeXTsIPwZ",
        "outputId": "60ee29ba-1ddc-4c6d-c913-3cf11c80359e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "746\n"
          ]
        }
      ],
      "source": [
        "print(count_spam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hyyl1LqIXMl",
        "outputId": "2ffc64b5-071b-47f1-ebea-8d48f7a8b5ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4617\n",
            "5363\n"
          ]
        }
      ],
      "source": [
        "print(count_ham)\n",
        "print(len(datos_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJrPI1zBGuPj",
        "outputId": "d42aabe5-d2f9-4dba-f021-66187f3e468c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-) ok. I feel like john lennon.\n"
          ]
        }
      ],
      "source": [
        "#Esta casilla contiene un ejemlpo de basura en la columna original de labels\n",
        "print(original_labels[3035])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-D8TF97Mwbs"
      },
      "source": [
        "A continuación se procesarán los datos para dejarlos en el formato adecuado para que BERT pueda trabajar con ellos, en particular:\n",
        "\n",
        "1. Cada \"correo\" debe comenzar y terminar con los tokens especiales [CLS] y [SEP], respectivamente.\n",
        "2. Se le aplicará padding a cada uno de los correos, su simbolo especial es [PAD] y su id es 0\n",
        "3. La función \"encode\" realiza el trabajo de tokenizar el texto y convertir cada token del correo a su id (Dichas ID's son fueron asignadas previamente)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnXG_NZe_9C1",
        "outputId": "2c1496f4-352b-4506-f174-810fc6a80fac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "Token IDs: [101, 2175, 2127, 18414, 17583, 2391, 1010, 4689, 1012, 1012, 2800, 2069, 1999, 11829, 2483, 1050, 2307, 2088, 2474, 1041, 28305, 1012, 1012, 1012, 25022, 2638, 2045, 2288, 26297, 28194, 1012, 1012, 1012, 102]\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in datos_texto:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', datos_texto[0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCc_BN1YJA24",
        "outputId": "e9fdd0e2-3f9a-4ca5-99d4-29339a705866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max sentence length:  221\n"
          ]
        }
      ],
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNeeTf5COhFV"
      },
      "source": [
        "Elegimos como tamaño de cada dato al largo del correo más grande, a los datos de menor tamaño se les aplicará padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaUWICAeItGL",
        "outputId": "e58d450c-5852-4fcd-8bb4-1a998d598203"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 221 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 221\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoz-zmhHJFIa"
      },
      "outputs": [],
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "\n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KUzzXcgZJq6-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#Acá deberiamos hacer un doble split con train_test_split: Uno con train/test, el otro sobre train-> train/test\n",
        "# Use 70% for training and 30% for validation.\n",
        "train_inputs, test_inputs, train_labels, test_labels = train_test_split(input_ids, datos_labels,\n",
        "                                                            random_state=2018, test_size=0.3)\n",
        "\n",
        "\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, datos_labels,\n",
        "                                                            random_state=2018, test_size=0.125)\n",
        "\n",
        "# Do the same for the masks.\n",
        "train_masks, test_masks, _, _ = train_test_split(attention_masks, datos_labels,\n",
        "                                             random_state=2018, test_size=0.3)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, datos_labels,\n",
        "                                             random_state=2018, test_size=0.125)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0yg-GgnLNep"
      },
      "outputs": [],
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype\n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "test_inputs = torch.tensor(test_inputs) #datos de test a tensores\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "test_masks = torch.tensor(test_masks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJ-Ac7HzNiYI"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it\n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our test set.\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Zif9FuzPV6f"
      },
      "source": [
        "Descargamos BERT pre-entrenado y lo enviamos a la GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "01e8ca1c4fc945569a8c57fa57322980",
            "baf5db36bb9d4732ad7c2930e904490c",
            "0b35aaf9fdd24b45ad3e78d74cc0260d",
            "6ec4cafbd13a49c5a1b6f40b817b0e73",
            "8a6d2c7b1598427c9914e41ccacb9dad",
            "ab666904112f4e429608b2c6c591665a",
            "0599a0d56ca1417d8ecd05f8e4104a3b",
            "52bdcbb4ae1847a0b5919766d7284211",
            "692ca8dac9764544ac74410db7867203",
            "e4c6d7b998fb405d920f9a9bec604a22",
            "c825ec3199fe45d38c335fbc34dd6e40"
          ]
        },
        "id": "W3M9RZaINl6t",
        "outputId": "f4f956f3-3b7b-4aa1-b36f-2fd0c8bbb200"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01e8ca1c4fc945569a8c57fa57322980",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
        "# linear classification layer on top.\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycbxdx8DPQM-"
      },
      "source": [
        "Detalles y componentes del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkFka8DgNqWf",
        "outputId": "507cb421-385c-40d2-b851-95487620016a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ],
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-mnlxeBNw_B",
        "outputId": "788154c5-3057-4515-e3a1-0c48f6ec7435"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch)\n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UduuSEmVN0HN"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93Pc7CJ4N2pw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USmVCXe3N6DY"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGJZLxmfP-1j"
      },
      "source": [
        "Entrenamiento y evaluación del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAccjhrpN8PL",
        "outputId": "c94b807d-e5ed-4a8b-c835-1d75fc622fe5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    147.    Elapsed: 0:00:44.\n",
            "  Batch    80  of    147.    Elapsed: 0:01:30.\n",
            "  Batch   120  of    147.    Elapsed: 0:02:14.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epcoh took: 0:02:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    147.    Elapsed: 0:00:45.\n",
            "  Batch    80  of    147.    Elapsed: 0:01:30.\n",
            "  Batch   120  of    147.    Elapsed: 0:02:15.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:02:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    147.    Elapsed: 0:00:45.\n",
            "  Batch    80  of    147.    Elapsed: 0:01:30.\n",
            "  Batch   120  of    147.    Elapsed: 0:02:15.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:02:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    147.    Elapsed: 0:00:45.\n",
            "  Batch    80  of    147.    Elapsed: 0:01:30.\n",
            "  Batch   120  of    147.    Elapsed: 0:02:15.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:02:45\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "  Validation took: 0:00:09\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to\n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because\n",
        "        # accumulating the gradients is \"convenient while training RNNs\".\n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here:\n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "\n",
        "        # The call to `model` always returns a tuple, so we need to pull the\n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value\n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "RYpL3iA98t2B",
        "outputId": "bb49d8d3-0074-4e65-d433-d5c1dd734eee"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEjgD1NBBiNp"
      },
      "source": [
        "A partir de aquí se evaluará el modelo con el conjunto de test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU6fIz7TTsxC",
        "outputId": "f20c7f81-1985-462e-fda7-99e8e3d5fbed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting labels for 1,609 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ],
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(test_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict\n",
        "for batch in test_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  # Telling the model not to compute or store gradients, saving memory and\n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None,\n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVEjlV1uDiMY",
        "outputId": "a7b983db-3e4c-4dc0-a501-ae2a20d49615"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "\n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\"\n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "\n",
        "  # Calculate and store the coef for this batch.\n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "  matthews_set.append(matthews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqFZrnA4Dtgg",
        "outputId": "830204a6-eca4-40fc-b70c-ec4720f293bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.8509629433967631,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.8459051693633014,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.8027729719194864,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.8958064164776167,\n",
              " 1.0,\n",
              " 0.9229582069908973,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9165151389911681,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matthews_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CjLJJxhD8g6"
      },
      "source": [
        "La métrica que se usa aquí es [\"Matthews correlation coefficient\" (MCC)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEf6C-rYDvTX",
        "outputId": "3ed46d66-ce91-429e-bc64-1f7781ab0372"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MCC: 0.984\n"
          ]
        }
      ],
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piVX_lq-T0t6"
      },
      "outputs": [],
      "source": [
        "def predict_bert(net, test_review, sequence_length=200):\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    test_ints = tokenize_review(test_review)\n",
        "\n",
        "    seq_length = sequence_length\n",
        "    features = pad_features(test_ints, seq_length)\n",
        "\n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "\n",
        "    batch_size = feature_tensor.size(0)\n",
        "\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    if(train_on_gpu):\n",
        "      feature_tensor = feature_tensor.cuda()\n",
        "\n",
        "    output, h = net(feature_tensor, h)\n",
        "\n",
        "    pred = torch.round(output.squeeze())\n",
        "    print('Valor predicho, antes del redondeo: {:.6f}'.format(output.item()))\n",
        "\n",
        "    # print custom response based on whether test_review is pos/neg\n",
        "    if(pred.item()==1):\n",
        "      print('spam')\n",
        "    else:\n",
        "      print('ham ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E27_l-OcOBm3"
      },
      "outputs": [],
      "source": [
        "seq_length=40\n",
        "text=\"\"\"\n",
        "MAY 9–10\n",
        "50% off\n",
        "Whatever your coding goals may be, now’s a great time to commit to achieving them.\n",
        "That’s why for the next two days, we’re offering 50% off annual memberships to Codecademy Pro. Just use promo code MAYSALE22 at checkout.\"\"\"\n",
        "print(len(text.split()))\n",
        "predict(model,text, len(text.split()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNQIEkyW1jHV"
      },
      "source": [
        "# Síntesis de resultados\n",
        "\n",
        "| Modelo               |    Accuracy           |\n",
        "|            ----------|:-------------:        |  \n",
        "| BERT                 |  0.99                 |\n",
        "\n",
        "| Modelo               |    Test Accuracy      | Spam Accuracy |Ham Accuracy|\n",
        "|            ----------|:-------------:        |:-------------:| :-----------:|\n",
        "| LSTM                 |     0.945              |  0.901     | 0.997            |  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSMxnPYDYRjK"
      },
      "source": [
        "#**Conclusión**\n",
        "En el presente trabajo se experimentó con dos tipos de modelos, redes neuronales recurrentes y transformers. Se logró evidenciar que las LSTM pueden ser lo suficientemente poderosas como para poder crear modelos que puedan resolver problemas que no son necesariamente tan especializados o complejos, en particular, el problema de clasificar si un correo es spam o no.Dicho esto, se puede concluir que, pese a que los transformers son modelos muy poderosos, dependiendo del problema que se quiera resolver, puede resultar más práctico y eficiente el uso de modelos más simples, ya que , en primer, hacer fine-tuning de estos modelos puede tomar más tiempo que entrenar un modelo más simple, debido a la gran cantidad de parámetros que posee y además, resulta más tedioso el pre-procesar los datos para que, en este caso, poder entregar a BERT los datos en el formato correcto (el modelo utilizado en esta tarea requería que los datos estuvieran en un formato determinado y del uso de máscaras que le dijeran al modelo cuando se está leyendo padding y cuando no). Aun así, el hecho de haber utilizado modelos que son parte del estado del arte resulta ser una experiencia valiosa."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "h99AJw5kx_nb",
        "0dT8HsqZyMnC",
        "EIJBXmS5qJU1",
        "tG0Er5YbLD89",
        "4CVVSRlCLAo8"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01e8ca1c4fc945569a8c57fa57322980": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_baf5db36bb9d4732ad7c2930e904490c",
              "IPY_MODEL_0b35aaf9fdd24b45ad3e78d74cc0260d",
              "IPY_MODEL_6ec4cafbd13a49c5a1b6f40b817b0e73"
            ],
            "layout": "IPY_MODEL_8a6d2c7b1598427c9914e41ccacb9dad"
          }
        },
        "0599a0d56ca1417d8ecd05f8e4104a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b35aaf9fdd24b45ad3e78d74cc0260d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52bdcbb4ae1847a0b5919766d7284211",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_692ca8dac9764544ac74410db7867203",
            "value": 440473133
          }
        },
        "52bdcbb4ae1847a0b5919766d7284211": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "692ca8dac9764544ac74410db7867203": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ec4cafbd13a49c5a1b6f40b817b0e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4c6d7b998fb405d920f9a9bec604a22",
            "placeholder": "​",
            "style": "IPY_MODEL_c825ec3199fe45d38c335fbc34dd6e40",
            "value": " 440M/440M [00:08&lt;00:00, 53.3MB/s]"
          }
        },
        "8a6d2c7b1598427c9914e41ccacb9dad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab666904112f4e429608b2c6c591665a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baf5db36bb9d4732ad7c2930e904490c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab666904112f4e429608b2c6c591665a",
            "placeholder": "​",
            "style": "IPY_MODEL_0599a0d56ca1417d8ecd05f8e4104a3b",
            "value": "Downloading: 100%"
          }
        },
        "c825ec3199fe45d38c335fbc34dd6e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4c6d7b998fb405d920f9a9bec604a22": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}